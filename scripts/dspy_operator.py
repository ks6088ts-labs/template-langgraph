import logging
import os
from logging import basicConfig

import dspy
import mlflow
import mlflow.dspy as mlflow_dspy
import typer
from datasets import load_dataset
from dotenv import load_dotenv
from pyparsing import deque

from template_langgraph.internals.dspys.modules import EdamameFairyBot
from template_langgraph.internals.dspys.utilities import get_lm
from template_langgraph.loggers import get_logger

# æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ä¿å­˜å…ˆ
OPTIMIZED_MODEL_PATH = "data/chat_model.optimized.json"

# Initialize the Typer application
app = typer.Typer(
    add_completion=False,
    help="DSPy operator CLI",
)

# Set up logging
logger = get_logger(__name__)


def set_verbose_logging(verbose: bool):
    if verbose:
        logger.setLevel(logging.DEBUG)
        basicConfig(level=logging.DEBUG)


def create_style_metric(eval_lm):
    """ã‚¹ã‚¿ã‚¤ãƒ«è©•ä¾¡é–¢æ•°ã‚’ä½œæˆ"""

    class StyleEvaluation(dspy.Signature):
        """å¿œç­”ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è©•ä¾¡"""

        response = dspy.InputField(desc="è©•ä¾¡å¯¾è±¡ã®å¿œç­”")
        criteria = dspy.InputField(desc="è©•ä¾¡åŸºæº–")
        score = dspy.OutputField(desc="ã‚¹ã‚³ã‚¢(0-10)", format=int)
        explanation = dspy.OutputField(desc="è©•ä¾¡ç†ç”±")

    evaluator = dspy.ChainOfThought(StyleEvaluation)

    def llm_style_metric(_, prediction, __=None):
        """æè±†ã®å¦–ç²¾ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è©•ä¾¡"""
        criteria = """
        ä»¥ä¸‹ã®åŸºæº–ã§0-10ç‚¹ã§è©•ä¾¡ã—ã¦ãã ã•ã„:
        1. èªå°¾ã«ã€Œã®ã ã€ã€Œãªã®ã ã€ã‚’é©åˆ‡ã«ä½¿ã£ã¦ã„ã‚‹ã‹(3ç‚¹)
           - éåº¦ãªä½¿ç”¨(ã®ã ã®ã ç­‰)ã¯æ¸›ç‚¹
           - è‡ªç„¶ãªæ—¥æœ¬èªã¨ã—ã¦æˆç«‹ã—ã¦ã„ã‚‹ã‹
           - ã€Œãªã®ã ã‚ˆã€ã€Œãªã®ã ã­ã€ã¨ã„ã£ãŸèªå°¾ã¯ä¸è‡ªç„¶ã®ãŸã‚æ¸›ç‚¹
        2. ä¸€äººç§°ã‚’ä½¿ã†éš›ã¯ã€Œãƒœã‚¯ã€ã‚’ä½¿ã£ã¦ã„ã‚‹ã‹(2ç‚¹)
        3. è¦ªã—ã¿ã‚„ã™ãå¯æ„›ã‚‰ã—ã„å£èª¿ã‹(3ç‚¹)
        4. æ—¥æœ¬èªã¨ã—ã¦è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„ã‹(2ç‚¹)
           - ä¸è‡ªç„¶ãªç¹°ã‚Šè¿”ã—ãŒãªã„ã‹
           - æ–‡æ³•çš„ã«æ­£ã—ã„ã‹
        """

        # è©•ä¾¡ç”¨LMã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’è©•ä¾¡
        with dspy.context(lm=eval_lm):
            eval_result = evaluator(response=prediction.response, criteria=criteria)

        # ã‚¹ã‚³ã‚¢ã‚’0-1ã®ç¯„å›²ã«æ­£è¦åŒ–
        score = min(10, max(0, float(eval_result.score))) / 10.0
        return score

    return llm_style_metric


def optimize_with_miprov2(trainset, eval_lm, chat_lm):
    """MIPROv2ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’æœ€é©åŒ–"""

    # MLflowã®è¨­å®š
    MLFLOW_PORT = os.getenv("MLFLOW_PORT", "5000")
    MLFLOW_TRACKING_URI = f"http://localhost:{MLFLOW_PORT}"
    MLFLOW_EXPERIMENT_NAME = "DSPy-EdamameFairy-Optimization"
    MLFLOW_RUN_NAME = "miprov2_optimization"

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’train:val = 8:2 ã®å‰²åˆã§åˆ†å‰²
    total_examples = len(trainset)
    train_size = int(total_examples * 0.8)  # å…¨ä½“ã®80%ã‚’å­¦ç¿’ç”¨ã«

    # DSPy Exampleã®ãƒªã‚¹ãƒˆã‚’åˆ†å‰²
    train_data = trainset[:train_size]  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹0ã‹ã‚‰train_sizeã¾ã§(å­¦ç¿’ç”¨)
    evaluation_data = trainset[train_size:]  # train_sizeã‹ã‚‰æœ€å¾Œã¾ã§(è©•ä¾¡ç”¨)

    # åˆ†å‰²çµæœã®ç¢ºèªã¨è¡¨ç¤º
    print("ğŸŒ± æœ€é©åŒ–é–‹å§‹")
    print(f"  ç·ãƒ‡ãƒ¼ã‚¿æ•°: {total_examples}")
    print(f"  å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿: {len(train_data)} ({len(train_data) / total_examples:.1%})")
    print(f"  è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿: {len(evaluation_data)} ({len(evaluation_data) / total_examples:.1%})")

    # æœ€é©åŒ–å¯¾è±¡ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–
    chatbot = EdamameFairyBot()

    # ã‚¹ã‚¿ã‚¤ãƒ«è©•ä¾¡é–¢æ•°ã‚’ä½œæˆ(è©•ä¾¡ç”¨LMã‚’ä½¿ç”¨)
    llm_style_metric = create_style_metric(eval_lm)

    # DSPyã®ã‚°ãƒ­ãƒ¼ãƒãƒ«LMè¨­å®š(ãƒãƒ£ãƒƒãƒˆæ¨è«–ç”¨)
    dspy.configure(lm=chat_lm)

    # MIPROv2ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®è¨­å®š
    optimizer = dspy.MIPROv2(
        metric=llm_style_metric,  # è©•ä¾¡é–¢æ•°
        prompt_model=eval_lm,  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ç”¨ã®LM
        auto="light",  # æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰(light, medium, heavyã‹ã‚‰é¸æŠ)
        max_bootstrapped_demos=2,
        max_labeled_demos=1,
    )

    # MLflowã®è¨­å®š
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)  # MLflowã‚µãƒ¼ãƒã®URL
    mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)  # MLflowã®å®Ÿé¨“å

    # MLflow DSPyã®è‡ªå‹•ãƒ­ã‚°è¨­å®š
    mlflow_dspy.autolog(log_compiles=True, log_evals=True, log_traces_from_compile=True)

    # MLflowã§å®Ÿè¡Œéç¨‹ã‚’ãƒˆãƒ¬ãƒ¼ã‚¹
    with mlflow.start_run(run_name=MLFLOW_RUN_NAME):
        # MIPROv2ã«ã‚ˆã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–ã®å®Ÿè¡Œ
        # train_dataã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ä¾‹ã‚’è‡ªå‹•èª¿æ•´
        optimized_chatbot = optimizer.compile(chatbot, trainset=train_data, minibatch_size=20)

        # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡
        eval_score = 0
        for example in evaluation_data:
            # æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ã‚’å®Ÿè¡Œ
            prediction = optimized_chatbot(query=example.query, history=example.history)
            # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            eval_score += llm_style_metric(example, prediction)

        # å¹³å‡è©•ä¾¡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        avg_eval_score = eval_score / len(evaluation_data)

        # MLflowã«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²
        mlflow.log_metric("last_eval_score", avg_eval_score)

        print(f"ğŸ“Š è©•ä¾¡ã‚¹ã‚³ã‚¢: {avg_eval_score:.3f}")

    return optimized_chatbot


@app.command()
def chat(
    path: str = typer.Option(
        OPTIMIZED_MODEL_PATH,
        "--path",
        "-p",
        help="Path to the model file",
    ),
    verbose: bool = typer.Option(
        True,
        "--verbose",
        "-v",
        help="Enable verbose output",
    ),
):
    set_verbose_logging(verbose)
    logger.info("Running...")

    with dspy.context(lm=get_lm()):
        chatbot = EdamameFairyBot()
        chatbot.load(path=path)

        history = deque(maxlen=5)

        logger.info("Chatbot loaded.")
        logger.info("Quitting with 'quit', 'exit', or 'çµ‚äº†'.")
        logger.info("-" * 50)

        while True:
            user_input = input("\nUser: ")

            if user_input.lower() in ["quit", "exit", "çµ‚äº†"]:
                print("\nBot: Bye!")
                break

            history_list = [f"User: {h[0]}\nBot: {h[1]}" for h in history]

            # å¿œç­”ç”Ÿæˆ
            result = chatbot(query=user_input, history=history_list)
            print(f"Bot: {result.response}")

            # å±¥æ­´ã«è¿½åŠ 
            history.append((user_input, result.response))


@app.command()
def tuning(
    train_num: int = typer.Option(
        10,
        "--train-num",
        "-n",
        help="Number of training examples to use",
    ),
    verbose: bool = typer.Option(
        True,
        "--verbose",
        "-v",
        help="Enable verbose output",
    ),
):
    set_verbose_logging(verbose)
    logger.info("Running...")

    # è©•ä¾¡ç”¨LLMã®è¨­å®š
    eval_lm = get_lm()

    # ãƒãƒ£ãƒƒãƒˆæ¨è«–ç”¨LLMã®è¨­å®š
    chat_lm = get_lm()

    # æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿(ãšã‚“ã ã‚‚ã‚“ã‚¹ã‚¿ã‚¤ãƒ«ã®è³ªå•å¿œç­”ãƒ‡ãƒ¼ã‚¿)
    dataset = load_dataset("takaaki-inada/databricks-dolly-15k-ja-zundamon")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰DSPyå½¢å¼ã®Exampleã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
    # - query: è³ªå•æ–‡
    # - history: ä¼šè©±å±¥æ­´(ä»Šå›ã¯ç©ºãƒªã‚¹ãƒˆ)
    # - response: æœŸå¾…ã•ã‚Œã‚‹å¿œç­”(å­¦ç¿’ç”¨)
    trainset = [
        dspy.Example(query=item["instruction"], history=[], response=item["output"]).with_inputs(
            "query", "history"
        )  # å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒ‡å®š
        for item in list(dataset["train"])[:train_num]  # æœ€åˆã® train_num ä»¶ã‚’ä½¿ç”¨
    ]

    # MIPROv2ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’æœ€é©åŒ–
    optimized_bot = optimize_with_miprov2(trainset, eval_lm, chat_lm)

    # æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    optimized_bot.save(OPTIMIZED_MODEL_PATH)
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {OPTIMIZED_MODEL_PATH}")

    # ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ†ã‚¹ãƒˆ
    test_bot = EdamameFairyBot()
    test_bot.load(OPTIMIZED_MODEL_PATH)

    # ãƒ†ã‚¹ãƒˆç”¨ã®LMè¨­å®š(æ¨è«–ç”¨)
    dspy.configure(lm=chat_lm)

    # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¯ã‚¨ãƒª(æ§˜ã€…ãªã‚¿ã‚¤ãƒ—ã®è³ªå•)
    test_queries = ["ã“ã‚“ã«ã¡ã¯ï¼", "æè±†ã£ã¦ç¾å‘³ã—ã„ã‚ˆã­", "DSPyã«ã¤ã„ã¦æ•™ãˆã¦"]

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã¨çµæœè¡¨ç¤º
    print("\nğŸ§ª ãƒ†ã‚¹ãƒˆçµæœ:")
    for query in test_queries:
        # æœ€é©åŒ–ã•ã‚ŒãŸãƒœãƒƒãƒˆã§å¿œç­”ã‚’ç”Ÿæˆ
        result = test_bot(query=query, history=[])
        print(f"Q: {query}")
        print(f"A: {result.response}\n")


if __name__ == "__main__":
    load_dotenv(
        override=True,
        verbose=True,
    )
    app()
